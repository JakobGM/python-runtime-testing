\documentclass{article}

\usepackage[utf8]{inputenc}
\usepackage{amsmath, amssymb}
\usepackage{hyperref}
\usepackage{graphicx}
\usepackage{bm}

\renewcommand{\thesection}{\arabic{section}.}

% \newcommand\given[1][]{\:#1\vert\:}
% \newcommand{\N}{\mathbb{N}}
%\newcommand{\E}{\mathrm{E}}
% \newcommand{\P}{\mathrm{P}}
% \newcommand{\Var}{\mathrm{Var}}
% \newcommand{\Cov}{\mathrm{Cov}}
% \newcommand{\me}{\mathrm{e}}

\title{TMA4267 Design of Experiment}
\author{Øyvind Klåpbakken, Jakob Martinussen}
\date{Spring 2017}

\begin{document}

\maketitle
\tableofcontents

<<echo=FALSE,message=FALSE,warning=FALSE>>=
read_chunk("R-code/R_for_latex.R")
@

<<setup,echo=FALSE,hide=TRUE,warning=FALSE,message=FALSE>>=
@

\section{Introduction}

\input{"latex/introduction.tex"}

\section{Problem}

\input{"latex/problem.tex"}

\section{Analysis}

The first step of the analysis involves fitting the full model. This produces estimates for $\mathbf{\beta}$, but the standard error of the individual ${\beta}_k$ can not be computed due to the degrees of freedom, $n - p$, being zero. Because of this the significant| covariates can not be found in the traditional way. An alternative approach must therefore be taken. Lenth provided a method for estimating which covariates are significant. This method is implemented in the code, see the function \texttt{get\_lenth}. Lenth's approach reveals that the four factor interaction isn't significant for any reasonable significance level. This, in addition with the unclear meaning of such an interaction leads us to drop the four factor interaction from the model in order to obtain a degree of freedom. 

<<full_model>>=
@

Fitting a new, reduced model without the four factor interaction reveals that none of three factor interactions are significant either. One can therefore proceed with a model with only one - and two - factor interactions. This has the benefit of enabling us to make plots of the residuals in order to evaluate the correctness of the assumptions made when constructing a linear model. 

<<reduced_model_1>>=
@

Before one proceeds to constructing the final model it is sensible to consider how a transformation of the response could impact the fit of the model. A widely used transformation is the Box-Cox transformation. The value that maximizes the log-likelihood function calculated by \texttt{boxcox} is chosen as $\lambda$ is the transformation given by the following equation. $T_{new}$ denotes the new response. $T$ denotes the original response.

\begin{equation}
T_{new} = \frac{T^{\lambda} - 1}{\lambda}
\end{equation}

This procedure is carried out in the code. Lambda is found by the use of \texttt{get{\_}lambda}.

<<reduced_model_2>>=
@

A new model with the transformed data is then fitted. Calling \texttt{summary} on the model, as done in the code, returns a overview of the most important properties of the model. $R^2$ is very high, but this is in part caused by the large number of covariates. This is indicated by $R^2_{adj}$. 

<<reduced_model_2_tf>>=
@

\section{Conclusion}

\input{"latex/conclusion.tex"}

\end{document}